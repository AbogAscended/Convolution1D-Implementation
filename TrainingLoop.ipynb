{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T21:54:45.914146Z",
     "start_time": "2024-07-12T21:54:44.961511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#needed imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from mnist1d.data import make_dataset, get_dataset_args\n",
    "from Convo1D import Convo"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T21:54:46.613312Z",
     "start_time": "2024-07-12T21:54:45.914934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#set up data with mnist1d module then turn each needed part into a tensor and then dataloader\n",
    "args = get_dataset_args()\n",
    "data = make_dataset(args)\n",
    "train_data_x = data['x'].transpose()\n",
    "train_data_y = data['y']\n",
    "val_data_x = data['x_test'].transpose()\n",
    "val_data_y = data['y_test']\n",
    "x_train = torch.tensor(train_data_x.transpose().astype('float32'))\n",
    "y_train = torch.tensor(train_data_y.astype('long')).long()\n",
    "x_val= torch.tensor(val_data_x.transpose().astype('float32'))\n",
    "y_val = torch.tensor(val_data_y.astype('long')).long()\n",
    "data_loader = DataLoader(TensorDataset(x_train,y_train), batch_size=32, shuffle=True)"
   ],
   "id": "7bdae284370848ec",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T21:54:47.104077Z",
     "start_time": "2024-07-12T21:54:46.613984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#move model to gpu\n",
    "model = Convo().to('cuda')\n",
    "#initialize weights\n",
    "model.weights_init()\n",
    "#set optimizer to SGD with adjustable hyperparams\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.15, momentum=0.8, weight_decay=0.0001)\n",
    "#set loss to cross entropy\n",
    "lossfn = nn.CrossEntropyLoss()\n",
    "#set step lr adjuster with respective hyperparams to be adjusted\n",
    "scheduler = StepLR(optimizer, step_size=40, gamma=0.95)"
   ],
   "id": "ada311b5a97acdf9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T21:55:03.187261Z",
     "start_time": "2024-07-12T21:54:47.104911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_epoch = 200\n",
    "# store the loss and the % correct at each epoch\n",
    "losses_train = np.zeros(n_epoch)\n",
    "errors_train = np.zeros(n_epoch)\n",
    "losses_val = np.zeros(n_epoch)\n",
    "errors_val = np.zeros(n_epoch)\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "  # loop over batches\n",
    "  for i, data in enumerate(data_loader):\n",
    "    # retrieve inputs and labels for this batch and move to gpu\n",
    "    x_batch, y_batch = data\n",
    "    x_batch = x_batch.to('cuda')\n",
    "    y_batch = y_batch.to('cuda')\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    # forward pass\n",
    "    pred = model(x_batch[:,None,:])\n",
    "    # compute the loss\n",
    "    loss = lossfn(pred, y_batch)\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    # SGD update\n",
    "    optimizer.step()\n",
    "\n",
    "  # Run whole dataset to get statistics to understand how training is going wrt hyperparams\n",
    "  x_train = x_train.to('cuda')\n",
    "  x_val = x_val.to('cuda')\n",
    "  y_val = y_val.to('cuda')\n",
    "  y_train = y_train.to('cuda')\n",
    "  pred_train = model(x_train[:,None,:])\n",
    "  pred_val = model(x_val[:,None,:])\n",
    "  _, predicted_train_class = torch.max(pred_train.data, 1)\n",
    "  _, predicted_val_class = torch.max(pred_val.data, 1)\n",
    "  errors_train[epoch] = 100 - 100 * (predicted_train_class == y_train).float().sum() / len(y_train)\n",
    "  errors_val[epoch]= 100 - 100 * (predicted_val_class == y_val).float().sum() / len(y_val)\n",
    "  losses_train[epoch] = lossfn(pred_train, y_train).item()\n",
    "  losses_val[epoch]= lossfn(pred_val, y_val).item()\n",
    "  print(f'Epoch {epoch:5d}, train loss {losses_train[epoch]:.6f}, train error {errors_train[epoch]:3.2f},  val loss {losses_val[epoch]:.6f}, percent error {errors_val[epoch]:3.2f}')\n",
    "  \n",
    "  #tell scheduler it might want to update\n",
    "  scheduler.step()"
   ],
   "id": "3ed0b4e8a8889e77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0, train loss 2.232693, train error 81.07,  val loss 2.242393, percent error 81.70\n",
      "Epoch     1, train loss 2.153369, train error 71.20,  val loss 2.169378, percent error 72.60\n",
      "Epoch     2, train loss 2.081299, train error 61.97,  val loss 2.095272, percent error 63.10\n",
      "Epoch     3, train loss 2.088432, train error 62.60,  val loss 2.099898, percent error 64.60\n",
      "Epoch     4, train loss 2.076801, train error 62.72,  val loss 2.083306, percent error 63.90\n",
      "Epoch     5, train loss 2.032767, train error 57.05,  val loss 2.040206, percent error 58.00\n",
      "Epoch     6, train loss 2.029868, train error 56.60,  val loss 2.037768, percent error 57.80\n",
      "Epoch     7, train loss 2.016539, train error 56.12,  val loss 2.036477, percent error 58.10\n",
      "Epoch     8, train loss 2.014074, train error 55.82,  val loss 2.032438, percent error 57.50\n",
      "Epoch     9, train loss 2.008653, train error 55.37,  val loss 2.041232, percent error 58.50\n",
      "Epoch    10, train loss 2.007514, train error 55.15,  val loss 2.033384, percent error 57.60\n",
      "Epoch    11, train loss 2.013450, train error 55.75,  val loss 2.048768, percent error 59.60\n",
      "Epoch    12, train loss 1.956819, train error 49.37,  val loss 1.990400, percent error 52.10\n",
      "Epoch    13, train loss 1.942277, train error 48.47,  val loss 1.996049, percent error 54.40\n",
      "Epoch    14, train loss 1.909091, train error 44.27,  val loss 1.954406, percent error 49.70\n",
      "Epoch    15, train loss 1.940497, train error 47.97,  val loss 1.962090, percent error 50.10\n",
      "Epoch    16, train loss 1.895457, train error 43.37,  val loss 1.927059, percent error 46.80\n",
      "Epoch    17, train loss 1.890981, train error 43.00,  val loss 1.929558, percent error 47.60\n",
      "Epoch    18, train loss 1.844787, train error 38.40,  val loss 1.870161, percent error 40.00\n",
      "Epoch    19, train loss 1.827248, train error 36.67,  val loss 1.869454, percent error 40.80\n",
      "Epoch    20, train loss 1.814099, train error 35.25,  val loss 1.857005, percent error 38.90\n",
      "Epoch    21, train loss 1.884535, train error 42.27,  val loss 1.905722, percent error 44.40\n",
      "Epoch    22, train loss 1.753865, train error 29.12,  val loss 1.789111, percent error 33.00\n",
      "Epoch    23, train loss 1.687075, train error 22.07,  val loss 1.715886, percent error 25.30\n",
      "Epoch    24, train loss 1.684037, train error 21.85,  val loss 1.715597, percent error 25.30\n",
      "Epoch    25, train loss 1.687975, train error 22.57,  val loss 1.728614, percent error 26.60\n",
      "Epoch    26, train loss 1.735799, train error 27.38,  val loss 1.761889, percent error 29.80\n",
      "Epoch    27, train loss 1.692167, train error 23.20,  val loss 1.730919, percent error 27.10\n",
      "Epoch    28, train loss 1.646280, train error 18.32,  val loss 1.683791, percent error 22.00\n",
      "Epoch    29, train loss 1.643581, train error 18.10,  val loss 1.660089, percent error 19.70\n",
      "Epoch    30, train loss 1.659242, train error 19.92,  val loss 1.689618, percent error 23.10\n",
      "Epoch    31, train loss 1.637667, train error 17.42,  val loss 1.671610, percent error 21.20\n",
      "Epoch    32, train loss 1.643145, train error 18.15,  val loss 1.662595, percent error 20.00\n",
      "Epoch    33, train loss 1.633868, train error 17.15,  val loss 1.667504, percent error 20.60\n",
      "Epoch    34, train loss 1.675147, train error 21.25,  val loss 1.695736, percent error 23.40\n",
      "Epoch    35, train loss 1.644630, train error 18.50,  val loss 1.666173, percent error 20.50\n",
      "Epoch    36, train loss 1.682017, train error 22.00,  val loss 1.719932, percent error 26.10\n",
      "Epoch    37, train loss 1.624078, train error 16.17,  val loss 1.648598, percent error 18.80\n",
      "Epoch    38, train loss 1.626844, train error 16.42,  val loss 1.643498, percent error 18.10\n",
      "Epoch    39, train loss 1.643732, train error 18.35,  val loss 1.663074, percent error 20.10\n",
      "Epoch    40, train loss 1.620957, train error 15.87,  val loss 1.651449, percent error 19.10\n",
      "Epoch    41, train loss 1.628285, train error 16.65,  val loss 1.648658, percent error 18.90\n",
      "Epoch    42, train loss 1.643040, train error 18.22,  val loss 1.674875, percent error 21.10\n",
      "Epoch    43, train loss 1.620319, train error 15.95,  val loss 1.639089, percent error 17.80\n",
      "Epoch    44, train loss 1.613496, train error 15.20,  val loss 1.633202, percent error 17.30\n",
      "Epoch    45, train loss 1.640967, train error 17.90,  val loss 1.670892, percent error 21.10\n",
      "Epoch    46, train loss 1.612721, train error 15.17,  val loss 1.637916, percent error 17.80\n",
      "Epoch    47, train loss 1.620632, train error 16.07,  val loss 1.632579, percent error 16.80\n",
      "Epoch    48, train loss 1.628828, train error 16.80,  val loss 1.652123, percent error 19.10\n",
      "Epoch    49, train loss 1.615475, train error 15.37,  val loss 1.644183, percent error 18.60\n",
      "Epoch    50, train loss 1.630402, train error 16.80,  val loss 1.662188, percent error 20.10\n",
      "Epoch    51, train loss 1.604108, train error 14.37,  val loss 1.628319, percent error 16.80\n",
      "Epoch    52, train loss 1.644884, train error 18.37,  val loss 1.668234, percent error 20.80\n",
      "Epoch    53, train loss 1.603306, train error 14.25,  val loss 1.634055, percent error 17.20\n",
      "Epoch    54, train loss 1.624220, train error 16.20,  val loss 1.657393, percent error 19.90\n",
      "Epoch    55, train loss 1.604408, train error 14.27,  val loss 1.634499, percent error 17.40\n",
      "Epoch    56, train loss 1.619549, train error 15.72,  val loss 1.630410, percent error 16.90\n",
      "Epoch    57, train loss 1.609086, train error 14.77,  val loss 1.634798, percent error 17.30\n",
      "Epoch    58, train loss 1.598353, train error 13.60,  val loss 1.617837, percent error 15.50\n",
      "Epoch    59, train loss 1.597925, train error 13.52,  val loss 1.623436, percent error 16.20\n",
      "Epoch    60, train loss 1.613893, train error 15.25,  val loss 1.628854, percent error 16.60\n",
      "Epoch    61, train loss 1.598969, train error 13.75,  val loss 1.629035, percent error 16.70\n",
      "Epoch    62, train loss 1.605824, train error 14.45,  val loss 1.619920, percent error 15.90\n",
      "Epoch    63, train loss 1.606216, train error 14.55,  val loss 1.623973, percent error 16.00\n",
      "Epoch    64, train loss 1.600049, train error 13.85,  val loss 1.618573, percent error 15.80\n",
      "Epoch    65, train loss 1.612423, train error 15.00,  val loss 1.623135, percent error 16.20\n",
      "Epoch    66, train loss 1.604166, train error 14.35,  val loss 1.638840, percent error 17.70\n",
      "Epoch    67, train loss 1.611552, train error 15.00,  val loss 1.638924, percent error 17.70\n",
      "Epoch    68, train loss 1.596250, train error 13.45,  val loss 1.622476, percent error 16.20\n",
      "Epoch    69, train loss 1.595954, train error 13.47,  val loss 1.609015, percent error 14.70\n",
      "Epoch    70, train loss 1.600773, train error 14.05,  val loss 1.623572, percent error 16.10\n",
      "Epoch    71, train loss 1.595797, train error 13.52,  val loss 1.617265, percent error 15.50\n",
      "Epoch    72, train loss 1.593266, train error 13.20,  val loss 1.611414, percent error 14.80\n",
      "Epoch    73, train loss 1.591014, train error 12.85,  val loss 1.616655, percent error 15.50\n",
      "Epoch    74, train loss 1.591788, train error 13.02,  val loss 1.612164, percent error 15.10\n",
      "Epoch    75, train loss 1.590887, train error 12.95,  val loss 1.607016, percent error 14.90\n",
      "Epoch    76, train loss 1.615502, train error 15.55,  val loss 1.638937, percent error 17.70\n",
      "Epoch    77, train loss 1.583041, train error 12.10,  val loss 1.611944, percent error 14.90\n",
      "Epoch    78, train loss 1.589905, train error 12.82,  val loss 1.610228, percent error 14.70\n",
      "Epoch    79, train loss 1.603815, train error 14.20,  val loss 1.631794, percent error 16.90\n",
      "Epoch    80, train loss 1.598185, train error 13.72,  val loss 1.630365, percent error 16.70\n",
      "Epoch    81, train loss 1.654623, train error 19.30,  val loss 1.680911, percent error 21.80\n",
      "Epoch    82, train loss 1.599107, train error 13.82,  val loss 1.629059, percent error 16.70\n",
      "Epoch    83, train loss 1.596737, train error 13.65,  val loss 1.623384, percent error 16.30\n",
      "Epoch    84, train loss 1.591697, train error 13.05,  val loss 1.621034, percent error 16.10\n",
      "Epoch    85, train loss 1.594882, train error 13.32,  val loss 1.614240, percent error 15.20\n",
      "Epoch    86, train loss 1.604291, train error 14.27,  val loss 1.639033, percent error 17.80\n",
      "Epoch    87, train loss 1.588063, train error 12.67,  val loss 1.626652, percent error 16.60\n",
      "Epoch    88, train loss 1.584377, train error 12.32,  val loss 1.608083, percent error 14.40\n",
      "Epoch    89, train loss 1.586277, train error 12.55,  val loss 1.610263, percent error 14.90\n",
      "Epoch    90, train loss 1.588666, train error 12.70,  val loss 1.618298, percent error 15.70\n",
      "Epoch    91, train loss 1.586031, train error 12.55,  val loss 1.621754, percent error 16.20\n",
      "Epoch    92, train loss 1.581424, train error 12.00,  val loss 1.612132, percent error 15.00\n",
      "Epoch    93, train loss 1.582773, train error 12.10,  val loss 1.618464, percent error 15.90\n",
      "Epoch    94, train loss 1.585222, train error 12.42,  val loss 1.609173, percent error 14.80\n",
      "Epoch    95, train loss 1.577974, train error 11.62,  val loss 1.606808, percent error 14.40\n",
      "Epoch    96, train loss 1.576419, train error 11.52,  val loss 1.605102, percent error 14.50\n",
      "Epoch    97, train loss 1.575851, train error 11.42,  val loss 1.607036, percent error 14.40\n",
      "Epoch    98, train loss 1.575617, train error 11.42,  val loss 1.608401, percent error 14.70\n",
      "Epoch    99, train loss 1.586365, train error 12.45,  val loss 1.622348, percent error 15.90\n",
      "Epoch   100, train loss 1.583181, train error 12.07,  val loss 1.612056, percent error 15.00\n",
      "Epoch   101, train loss 1.577615, train error 11.62,  val loss 1.603787, percent error 14.10\n",
      "Epoch   102, train loss 1.579951, train error 11.85,  val loss 1.607552, percent error 14.60\n",
      "Epoch   103, train loss 1.574679, train error 11.35,  val loss 1.606349, percent error 14.60\n",
      "Epoch   104, train loss 1.577001, train error 11.50,  val loss 1.609687, percent error 15.10\n",
      "Epoch   105, train loss 1.582724, train error 12.05,  val loss 1.617588, percent error 15.50\n",
      "Epoch   106, train loss 1.571807, train error 11.10,  val loss 1.605320, percent error 14.40\n",
      "Epoch   107, train loss 1.571528, train error 10.92,  val loss 1.602904, percent error 14.10\n",
      "Epoch   108, train loss 1.573528, train error 11.10,  val loss 1.608525, percent error 14.90\n",
      "Epoch   109, train loss 1.578240, train error 11.55,  val loss 1.609545, percent error 14.80\n",
      "Epoch   110, train loss 1.571315, train error 10.97,  val loss 1.610767, percent error 15.00\n",
      "Epoch   111, train loss 1.570236, train error 10.87,  val loss 1.608859, percent error 14.80\n",
      "Epoch   112, train loss 1.587892, train error 12.47,  val loss 1.630565, percent error 17.00\n",
      "Epoch   113, train loss 1.571922, train error 10.97,  val loss 1.607876, percent error 14.50\n",
      "Epoch   114, train loss 1.578557, train error 11.57,  val loss 1.611672, percent error 15.00\n",
      "Epoch   115, train loss 1.571482, train error 11.00,  val loss 1.607300, percent error 14.60\n",
      "Epoch   116, train loss 1.576199, train error 11.47,  val loss 1.609082, percent error 14.70\n",
      "Epoch   117, train loss 1.576889, train error 11.35,  val loss 1.611350, percent error 14.80\n",
      "Epoch   118, train loss 1.573904, train error 11.07,  val loss 1.607820, percent error 14.50\n",
      "Epoch   119, train loss 1.571728, train error 10.90,  val loss 1.602566, percent error 14.10\n",
      "Epoch   120, train loss 1.571183, train error 10.97,  val loss 1.603422, percent error 14.00\n",
      "Epoch   121, train loss 1.569799, train error 10.72,  val loss 1.603513, percent error 14.40\n",
      "Epoch   122, train loss 1.569996, train error 10.87,  val loss 1.604033, percent error 14.20\n",
      "Epoch   123, train loss 1.568155, train error 10.70,  val loss 1.600353, percent error 13.60\n",
      "Epoch   124, train loss 1.567157, train error 10.60,  val loss 1.604872, percent error 14.40\n",
      "Epoch   125, train loss 1.568261, train error 10.72,  val loss 1.599889, percent error 13.80\n",
      "Epoch   126, train loss 1.570229, train error 10.82,  val loss 1.604852, percent error 14.40\n",
      "Epoch   127, train loss 1.567023, train error 10.57,  val loss 1.606430, percent error 14.50\n",
      "Epoch   128, train loss 1.566726, train error 10.57,  val loss 1.603278, percent error 14.00\n",
      "Epoch   129, train loss 1.566474, train error 10.57,  val loss 1.604578, percent error 14.30\n",
      "Epoch   130, train loss 1.565998, train error 10.55,  val loss 1.602982, percent error 14.10\n",
      "Epoch   131, train loss 1.565929, train error 10.55,  val loss 1.605119, percent error 14.70\n",
      "Epoch   132, train loss 1.565710, train error 10.52,  val loss 1.605827, percent error 14.70\n",
      "Epoch   133, train loss 1.566080, train error 10.52,  val loss 1.606937, percent error 14.50\n",
      "Epoch   134, train loss 1.565731, train error 10.52,  val loss 1.606639, percent error 14.70\n",
      "Epoch   135, train loss 1.565810, train error 10.52,  val loss 1.606676, percent error 14.60\n",
      "Epoch   136, train loss 1.566145, train error 10.52,  val loss 1.609880, percent error 15.00\n",
      "Epoch   137, train loss 1.565738, train error 10.52,  val loss 1.604725, percent error 14.60\n",
      "Epoch   138, train loss 1.565938, train error 10.52,  val loss 1.604833, percent error 14.30\n",
      "Epoch   139, train loss 1.566744, train error 10.52,  val loss 1.608952, percent error 14.80\n",
      "Epoch   140, train loss 1.567235, train error 10.55,  val loss 1.606551, percent error 14.30\n",
      "Epoch   141, train loss 1.568285, train error 10.62,  val loss 1.607807, percent error 14.70\n",
      "Epoch   142, train loss 1.565812, train error 10.50,  val loss 1.605218, percent error 14.60\n",
      "Epoch   143, train loss 1.566192, train error 10.50,  val loss 1.605414, percent error 14.10\n",
      "Epoch   144, train loss 1.565966, train error 10.50,  val loss 1.605023, percent error 14.30\n",
      "Epoch   145, train loss 1.565705, train error 10.50,  val loss 1.606959, percent error 14.40\n",
      "Epoch   146, train loss 1.565568, train error 10.50,  val loss 1.607380, percent error 14.50\n",
      "Epoch   147, train loss 1.565539, train error 10.50,  val loss 1.607174, percent error 14.50\n",
      "Epoch   148, train loss 1.565625, train error 10.50,  val loss 1.607001, percent error 14.60\n",
      "Epoch   149, train loss 1.565848, train error 10.52,  val loss 1.607941, percent error 14.50\n",
      "Epoch   150, train loss 1.565489, train error 10.32,  val loss 1.607635, percent error 14.80\n",
      "Epoch   151, train loss 1.569912, train error 10.47,  val loss 1.616472, percent error 15.60\n",
      "Epoch   152, train loss 1.551660, train error 8.65,  val loss 1.591287, percent error 12.60\n",
      "Epoch   153, train loss 1.532821, train error 6.20,  val loss 1.572381, percent error 10.60\n",
      "Epoch   154, train loss 1.526866, train error 5.92,  val loss 1.572723, percent error 10.60\n",
      "Epoch   155, train loss 1.521027, train error 5.60,  val loss 1.573831, percent error 10.70\n",
      "Epoch   156, train loss 1.524487, train error 5.57,  val loss 1.572855, percent error 10.70\n",
      "Epoch   157, train loss 1.513090, train error 4.80,  val loss 1.553500, percent error 8.90\n",
      "Epoch   158, train loss 1.525354, train error 5.87,  val loss 1.572254, percent error 10.80\n",
      "Epoch   159, train loss 1.495687, train error 3.07,  val loss 1.538340, percent error 7.60\n",
      "Epoch   160, train loss 1.511468, train error 4.82,  val loss 1.555641, percent error 8.80\n",
      "Epoch   161, train loss 1.497118, train error 3.37,  val loss 1.543472, percent error 7.80\n",
      "Epoch   162, train loss 1.499401, train error 3.10,  val loss 1.559305, percent error 9.80\n",
      "Epoch   163, train loss 1.508220, train error 4.32,  val loss 1.559197, percent error 9.40\n",
      "Epoch   164, train loss 1.504569, train error 4.02,  val loss 1.549817, percent error 9.00\n",
      "Epoch   165, train loss 1.496019, train error 3.22,  val loss 1.546929, percent error 8.50\n",
      "Epoch   166, train loss 1.504583, train error 4.12,  val loss 1.559168, percent error 9.70\n",
      "Epoch   167, train loss 1.501017, train error 3.37,  val loss 1.555271, percent error 8.90\n",
      "Epoch   168, train loss 1.491658, train error 2.67,  val loss 1.549277, percent error 8.60\n",
      "Epoch   169, train loss 1.504400, train error 4.07,  val loss 1.549137, percent error 8.80\n",
      "Epoch   170, train loss 1.503332, train error 3.82,  val loss 1.556569, percent error 9.60\n",
      "Epoch   171, train loss 1.510328, train error 4.75,  val loss 1.553777, percent error 9.10\n",
      "Epoch   172, train loss 1.495208, train error 3.02,  val loss 1.549683, percent error 8.60\n",
      "Epoch   173, train loss 1.501014, train error 3.77,  val loss 1.553624, percent error 9.00\n",
      "Epoch   174, train loss 1.506277, train error 4.22,  val loss 1.554624, percent error 8.70\n",
      "Epoch   175, train loss 1.492069, train error 2.72,  val loss 1.543820, percent error 8.50\n",
      "Epoch   176, train loss 1.522405, train error 5.92,  val loss 1.576809, percent error 11.80\n",
      "Epoch   177, train loss 1.489686, train error 2.75,  val loss 1.541754, percent error 8.30\n",
      "Epoch   178, train loss 1.499439, train error 3.65,  val loss 1.552306, percent error 9.10\n",
      "Epoch   179, train loss 1.489296, train error 2.52,  val loss 1.541895, percent error 8.10\n",
      "Epoch   180, train loss 1.502695, train error 3.80,  val loss 1.553319, percent error 8.80\n",
      "Epoch   181, train loss 1.498476, train error 3.60,  val loss 1.553927, percent error 9.10\n",
      "Epoch   182, train loss 1.509723, train error 4.82,  val loss 1.554874, percent error 9.10\n",
      "Epoch   183, train loss 1.495495, train error 3.42,  val loss 1.545507, percent error 8.20\n",
      "Epoch   184, train loss 1.529777, train error 6.80,  val loss 1.575046, percent error 11.50\n",
      "Epoch   185, train loss 1.514043, train error 5.12,  val loss 1.548703, percent error 8.50\n",
      "Epoch   186, train loss 1.516270, train error 5.57,  val loss 1.558250, percent error 9.50\n",
      "Epoch   187, train loss 1.504728, train error 4.27,  val loss 1.551486, percent error 8.50\n",
      "Epoch   188, train loss 1.504664, train error 4.17,  val loss 1.556079, percent error 9.30\n",
      "Epoch   189, train loss 1.517680, train error 5.40,  val loss 1.566336, percent error 10.80\n",
      "Epoch   190, train loss 1.506624, train error 4.52,  val loss 1.563560, percent error 10.40\n",
      "Epoch   191, train loss 1.529810, train error 6.77,  val loss 1.572948, percent error 11.30\n",
      "Epoch   192, train loss 1.511545, train error 5.02,  val loss 1.556521, percent error 9.10\n",
      "Epoch   193, train loss 1.503819, train error 4.25,  val loss 1.551234, percent error 9.00\n",
      "Epoch   194, train loss 1.502672, train error 4.15,  val loss 1.553375, percent error 8.90\n",
      "Epoch   195, train loss 1.513193, train error 5.10,  val loss 1.550214, percent error 8.50\n",
      "Epoch   196, train loss 1.505144, train error 4.27,  val loss 1.545848, percent error 8.50\n",
      "Epoch   197, train loss 1.495116, train error 3.32,  val loss 1.531790, percent error 6.90\n",
      "Epoch   198, train loss 1.556471, train error 9.22,  val loss 1.609322, percent error 14.70\n",
      "Epoch   199, train loss 1.513437, train error 5.07,  val loss 1.561431, percent error 9.60\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
